/*
 * generated by Xtext 2.24.0
 */
package org.xtext.example.mydsl.generator

import org.eclipse.emf.ecore.resource.Resource
import org.eclipse.xtext.generator.AbstractGenerator
import org.eclipse.xtext.generator.IFileSystemAccess2
import org.eclipse.xtext.generator.IGeneratorContext
import org.xtext.example.mydsl.mmlg.AllVariables
import org.xtext.example.mydsl.mmlg.CSVSeparator
import org.xtext.example.mydsl.mmlg.CrossValidation
import org.xtext.example.mydsl.mmlg.DT
import org.xtext.example.mydsl.mmlg.FrameworkLang
import org.xtext.example.mydsl.mmlg.LogisticRegression
import org.xtext.example.mydsl.mmlg.MLAlgorithm
import org.xtext.example.mydsl.mmlg.MMLModel
import org.xtext.example.mydsl.mmlg.PredictorVariables
import org.xtext.example.mydsl.mmlg.RandomForest
import org.xtext.example.mydsl.mmlg.SVM
import org.xtext.example.mydsl.mmlg.SVMClassification
import org.xtext.example.mydsl.mmlg.SVMKernel
import org.xtext.example.mydsl.mmlg.TrainingTest
import org.xtext.example.mydsl.mmlg.ValidationMetric

/**
 * Generates code from your model files on save.
 * 
 * See https://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html#code-generation
 */
class MmlgGenerator extends AbstractGenerator {

	override void doGenerate(Resource resource, IFileSystemAccess2 fsa, IGeneratorContext context) {
		val m = resource.contents.get(0) as MMLModel
		var outputFileName = 'programm.py'
		
		val mlAlgorithm = m.getAlgorithm();
		if (mlAlgorithm !== null) {
		val frmwk = mlAlgorithm.getFramework();
		if (frmwk !== null && frmwk == FrameworkLang.R) 
			outputFileName = 'programm.R'
			
		}
		
		fsa.generateFile(outputFileName, compile_bis(m))
	}
	
	private def compile_bis(MMLModel m) {
		
				val dataInput = m.getInput();
				val fileLocation = dataInput.getFilelocation();

				val mlAlgorithm = m.getAlgorithm();
				var frmwk = FrameworkLang.SCIKIT; // default
				
				var algo = null as MLAlgorithm
				if (mlAlgorithm !== null) {
					algo = mlAlgorithm.getAlgorithm();
					frmwk = mlAlgorithm.getFramework();				
				}

				val DEFAULT_COLUMN_SEPARATOR = CSVSeparator.COMMA; // by default
				var csv_separator = DEFAULT_COLUMN_SEPARATOR;
				val parsingInstruction = dataInput.getParsingInstruction();
				if (parsingInstruction !== null) {
					println("parsing instruction..." + parsingInstruction);
					csv_separator = parsingInstruction.getSep();
					if (CSVSeparator.SEMI_COLON.equals(csv_separator)) {
						csv_separator = CSVSeparator.SEMI_COLON;
					} else if (CSVSeparator.COMMA.equals(csv_separator)) {
						csv_separator = CSVSeparator.COMMA;
					}
				}
				
				if (frmwk == FrameworkLang.SCIKIT) {

					var pythonImport = "import pandas as pd\n";
					pythonImport += "import sklearn\n";
					val csvReading = "mml_data = pd.read_csv(" + mkValueInSingleQuote(fileLocation) + ", sep="
							+ mkValueInSingleQuote(csv_separator.getLiteral()) + ")\n";
					var pandasCode = pythonImport + csvReading;
					if (mlAlgorithm === null)
						return pandasCode

					var algoML = "";
					println("algo");
					if (algo instanceof SVM) {
						println("SVM");
						algoML = "from sklearn import svm\n";
						val svm = algo as SVM;
						var gamma = svm.getGamma();
						if(gamma === null) {
							println("gamma non specifie");
							gamma = "auto_deprecated";
						}
						var C = svm.getC();
						if(C === null) {
							println("C non specifie");
							C = "1.0";
							
						}
						var kernel = svm.getKernel();
						var resKernel ="";
						if(kernel === null) { //pas de SVM classification spécifié
							println("SVMClassification non specifiee");
							resKernel = "rbf";
						}else {//
							println("SVMClassification specifiee");
							if (SVMKernel.LINEAR.equals(kernel)) {
								kernel = SVMKernel.LINEAR;
							} else if (SVMKernel.POLY.equals(kernel)) {
								kernel = SVMKernel.POLY;
								
							}else if (SVMKernel.RADIAL.equals(kernel)) {
								kernel = SVMKernel.RADIAL;
							}
							resKernel = kernel.getLiteral();
						}
						var svmClass = svm.getSvmclassification();
						var resClass = "";
						if(svmClass === null) { //no SVM classification specified
							println("SVMClassification non specified");
							resClass="";
						}else {//
							println("SVMClassification specified");
							if (SVMClassification.CCLASS.equals(svmClass)) {
								svmClass = SVMClassification.CCLASS;
							} else if (SVMClassification.NU_CLASS.equals(svmClass)) {
								svmClass = SVMClassification.NU_CLASS;
							}else if (SVMClassification.ONE_CLASS.equals(svmClass)) {
								svmClass = SVMClassification.ONE_CLASS;
							}
							resClass = svmClass.getLiteral();
						}
						algoML += "classifier = svm.SVC(gamma= " + gamma+",kernel='"+resKernel+"',C="+C+")\n";
						
					} else if (algo instanceof DT) {
						println("DT");
						var dt = algo as DT;
						var max_depth = "";
						if (dt.getMax_depth() != 0) {
							max_depth = Integer.toString(dt.getMax_depth());
						} else {
							max_depth = "None";
						}
						algoML = "from sklearn.tree import DecisionTreeClassifier \nclassifier = DecisionTreeClassifier(max_depth="
								+ max_depth + ")\n";
					} else if (algo instanceof LogisticRegression) {
						println("LogisticRegression");
						val lr = algo as LogisticRegression;
						algoML = "from sklearn.linear_model import LogisticRegression\n";
						algoML += "classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n";

					} else if (algo instanceof RandomForest) {
						println("RandomForest");
						val rf = algo as RandomForest;
						algoML = "from sklearn.ensemble import RandomForestClassifier\n";
						algoML += "classifier = RandomForestClassifier()\n";
					}
					println("Formula");
					val formula = m.getFormula();
					var codeFormulaX = "";
					var codeFormulaY = "";
					if (formula === null) { // si aucune formule n'a été donnée
						codeFormulaY = "Y = mml_data.iloc[:,-1]\n";
						codeFormulaX = "X = mml_data.iloc[:,:-1]\n";
					} else {// une formule a été donnée
						println("Formule donnee");
						val y = formula.getPredictive();
						val x = formula.getPredictors();
						if (y === null) { // if predictive is not filled
							println("Predictive non renseignee");
							codeFormulaY = "Y = mml_data.iloc[:,-1]\n";
							if (x instanceof AllVariables) {// all variables are explicatives
								codeFormulaX = "X = mml_data.iloc[:, :-1] \n";
							} else {// si PredictorVariables
								val xPred = x as PredictorVariables;
								// on initialise codeFormulaX
								if (xPred.getVars().get(0).getColName() !== null) {// c'est un string
									codeFormulaX = "Y = mml_data[[" + xPred.getVars().get(0).getColName();
								} else {// c'est un entier
									codeFormulaX = "X = mml_data.iloc[:,[" + xPred.getVars().get(0).getColumn();
								}
								for (var i = 1; i < xPred.getVars().size(); i++) {
									// xPred.getVars().get(i)
									if (xPred.getVars().get(i).getColName() !== null) {// c'est un string
										codeFormulaX += ",";
										codeFormulaX += xPred.getVars().get(i).getColName();
									} else {// integer
										codeFormulaX += ",";
										codeFormulaX += xPred.getVars().get(i).getColumn();
									}

								}
								if (xPred.getVars().get(0).getColName() !== null) {// c'est un string
									codeFormulaX += "]] \n";
								} else {// integer
									codeFormulaX += "]] \n";
								}

							}
						} else {// la prédictive a été donnée
							println("Predictive renseignee");
							if (y.getColName() != null) { // si colname est un string
								println("Predictive est un string");
								codeFormulaY = "Y = mml_data['" + y.getColName() + "'] \n";
								if (x instanceof AllVariables) {
									println("Toutes les variables sont explicatives");
									codeFormulaX = "X = mml_data.loc[:, ~mml_data.columns.isin(['"+ y.getColName() +"'])]\n";
								}
							} else { //// si colname est un int
								println("Predictive est un int");
								codeFormulaY = "Y = mml_data.iloc[:," + y.getColumn() + "] \n";
								if (x instanceof AllVariables) {
									println("Toutes les variables sont explicatives");
									codeFormulaX += "X = mml_data\n";
									codeFormulaX += "X.drop(X.columns["+y.getColumn()+"],axis=1,inplace=True)\n";
									  
								}
							}
								if (x instanceof PredictorVariables) {
									// PredictorVariables
									println("Des variables explicatives ont été données");
									val xPred = x as PredictorVariables;
									// on initialise codeFormulaX
									if (xPred.getVars().get(0).getColName() !== null) {// c'est un string
										println("Les variables explicatives sont des strings");
										codeFormulaX = "X = mml_data[['" + xPred.getVars().get(0).getColName()+"'";
									} else {// c'est un entier
										println("Les variables explicatives sont des entiers");
										codeFormulaX = "X = mml_data.iloc[:,[" + xPred.getVars().get(0).getColumn();
									}
									for (var i = 1; i < xPred.getVars().size(); i++) {
										// xPred.getVars().get(i)
										if (xPred.getVars().get(i).getColName() !== null) {// c'est un string
											codeFormulaX += ",'";
											codeFormulaX += xPred.getVars().get(i).getColName()+"'";
										} else {// c'est un entier
											codeFormulaX += ",";
											codeFormulaX += xPred.getVars().get(i).getColumn();
										}

									}
									if (xPred.getVars().get(0).getColName() != null) {// c'est un string
										codeFormulaX += "]] \n";
									} else {// c'est un entier
										codeFormulaX += "]] \n";
									}

								}


						}
					}
					println("Validation");
					/* LA VALIDATION */
					val validation = m.getValidation();
					val stratification = validation.getStratification();
					// LA METRIQUE
					// ValidationMetric metric = validation;
					var metricCode = "";
					val metric = validation.getMetric();
					println("Metrique");
					for (var i = 0; i < metric.size(); i++) {
						if (ValidationMetric.RECALL.equals(metric.get(i))) {
							metricCode += "print('recall = ')\n";
							metricCode += "print(recall)\n";
						} else if (ValidationMetric.PRECISION.equals(metric.get(i))) {
							metricCode += "print('precision = ')\n";
							metricCode += "print(precision)\n";
						} else if (ValidationMetric.F1.equals(metric.get(i))) {
							metricCode += "print('f1_score = ')\n";
							metricCode += "print(f1_score)\n";
						}
					}

					// LA STRATIFICATION
					var stratificationCode = "";
					println("Stratification");
					if (stratification instanceof CrossValidation) {// c'est de la crossValidation
						println("CrossValidation");
						val cross = stratification as CrossValidation;
						val numRep = cross.getNumber();
						// créer le x_train et le y_train
						stratificationCode += "from sklearn.model_selection import StratifiedKFold\n";
						stratificationCode += "skf = StratifiedKFold(n_splits=" + numRep + ", shuffle=True)\n";
						stratificationCode += "recall = 0\n";
						stratificationCode += "f1_score = 0\n";
						stratificationCode += "precision = 0\n";
						stratificationCode += "for train_indices, val_indices in skf.split(X, Y):\n";
						stratificationCode += "    x_train, x_test = X.iloc[train_indices,], X.iloc[val_indices,]\n";
						stratificationCode += "    y_train, y_test = Y[train_indices], Y[val_indices]\n";
						stratificationCode += "    classifier.fit(x_train,y_train)\n";
						stratificationCode += "    y_pred = classifier.predict(x_test)\n";
						stratificationCode += "    recall = recall + sklearn.metrics.recall_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";
						stratificationCode += "    precision = precision + sklearn.metrics.precision_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";
						stratificationCode += "    f1_score = f1_score + sklearn.metrics.f1_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";
						stratificationCode += "recall = recall /" + numRep + "\n";
						stratificationCode += "f1_score = f1_score /" + numRep + "\n";
						stratificationCode += "precision = precision /" + numRep + "\n";

						stratificationCode += metricCode + "\n";

						///////////// REVOIR CROSS VALIDATION
					} else {// c'est du TrainingTest
						println("TrainingTest");
						val trainTest = stratification as TrainingTest;
						val pourcentageTraining = trainTest.getNumber();
						val pourcentage = (100 - pourcentageTraining * 1.0 )/100;
						stratificationCode += "from sklearn.model_selection import train_test_split\n";
						stratificationCode += "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size="
								+ pourcentage + ")\n";
						stratificationCode += "classifier.fit(x_train,y_train)\n";
						stratificationCode += "y_pred = classifier.predict(x_test)\n";
						stratificationCode += "recall = sklearn.metrics.recall_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";
						stratificationCode += "precision = sklearn.metrics.precision_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";
						stratificationCode += "f1_score = sklearn.metrics.f1_score(y_test, y_pred, labels=None, pos_label=1, average=\'macro\')\n";


						stratificationCode += metricCode;
					}

					// variable predicitive par defaut est la derniere du tableau
					// FrameworkLang framework = mlAlgorithm.getFramework();
					pandasCode += "\nprint (mml_data)\n";
					pandasCode += codeFormulaY;
					pandasCode += codeFormulaX;
					pandasCode += algoML;
					pandasCode += stratificationCode;

					return pandasCode;
				}
				
					
				if (frmwk === FrameworkLang.R) { 
					var RcsvReading = "mml_data <- read.csv(" + mkValueInSingleQuote(fileLocation) + ", sep=" + mkValueInSingleQuote(csv_separator.getLiteral()) + ")\n";
					var RCode = RcsvReading;

					var RalgoML = "";
					println("algo");
					if (algo instanceof SVM) {
						println("SVM");
						var svm = algo as SVM;
						var gamma = svm.getGamma();
						if(gamma === null) {
							println("gamma non specifie");
							gamma = "1 / ncol(train)" ;
						}
						var C = svm.getC();
						if(C === null) {
							println("C non specifie");
							C = "1";
							
						}
						var kernel = svm.getKernel();
						var resKernel="";
						if(kernel === null) { //pas de SVM classification spécifié
							println("SVMClassification non specifiee");
							resKernel = "linear";
						}else {//
							println("SVMClassification specifiee");
							if (SVMKernel.LINEAR.equals(kernel)) {
								kernel = SVMKernel.LINEAR;
							} else if (SVMKernel.POLY.equals(kernel)) {
								kernel = SVMKernel.POLY;
								
							}else if (SVMKernel.RADIAL.equals(kernel)) {
								kernel = SVMKernel.RADIAL;
							}
							resKernel = kernel.getLiteral();
						}
						var svmClass = svm.getSvmclassification();
						var resClass="C-classification";
						if(svmClass == null) { //pas de SVM classification spécifié
							println("SVMClassification non specifiee");
						}else {//
							println("SVMClassification specifiee");
							if (SVMClassification.CCLASS.equals(svmClass)) {
								svmClass = SVMClassification.CCLASS;
							} else if (SVMClassification.NU_CLASS.equals(svmClass)) {
								svmClass = SVMClassification.NU_CLASS;
							}else if (SVMClassification.ONE_CLASS.equals(svmClass)) {
								svmClass = SVMClassification.ONE_CLASS;
							}
							resClass = svmClass.getLiteral();
						}
						//RalgoML += "install.packages(\'e1071\')\n";
						RalgoML += "library(e1071)\n";
						RalgoML += "classifier <- svm(formule,data=train,kernel=\'"+resKernel+"\',type = \'"+resClass+"\' , gamma="+gamma+",cost = "+C+")\n";
						
					} else if (algo instanceof DT) {
						println("DT");
						val dt = algo as DT;
						var max_depth = "";
						//RalgoML += "install.packages(\'rpart\')\n";
						RalgoML += "library(rpart)\n";
						if (dt.getMax_depth() != 0) {
							max_depth = Integer.toString(dt.getMax_depth());
							RalgoML += "ctrl <- rpart.control(maxdepth = "+max_depth+")\n";

						} else {
							RalgoML += "ctrl <- rpart.control()\n";
						}
						RalgoML += "classifier <- rpart(formule, method=\"class\", data=train,control = ctrl)\n";

					} else if (algo instanceof LogisticRegression) {
						println("LogisticRegression");
						val lr = algo as LogisticRegression;
						RalgoML += "install.packages(\'nnet\')\n";
						RalgoML = "library(nnet)\n";
						RalgoML += "classifier <- multinom(formule, data = train)\n";

					} else if (algo instanceof RandomForest) {
						println("RandomForest");
						val rf = algo as RandomForest;
						//RalgoML += "install.packages(\'randomForest\')\n";
						RalgoML = "library(randomForest)\n";
						RalgoML += "classifier <- randomForest(formule, data = train)\n";
					}
					println("Formule");
					val formulaR = m.getFormula();
					var nomY = "";
					var nomsX = "";
					var nbPredictive = "";
					if (formulaR == null) { // si aucune formule n'a été donnée
						nomY = "nomY = colnames(mml_data)[ncol(mml_data)]\n";
						nbPredictive = "nbPredictive = ncol(mml_data)\n";
						nomsX = "nomsX = \'.\'\n";
					} else {// une formule a été donnée
						println("Formule donnee");
						val y = formulaR.getPredictive();
						val x = formulaR.getPredictors();
						if (y == null) { // si la predictive n'a pas été renseignée
							println("Predictive non renseignee");
							nomY = "nomY = colnames(mml_data)[ncol(mml_data)]\n";
							nbPredictive = "nbPredictive = ncol(mml_data)\n";
							if (x instanceof AllVariables) {// toutes les variables sont explicatives
								nomsX = "nomsX = \'.\'\n";
							} else {// si PredictorVariables
								val xPred = x as PredictorVariables;
								// on initialise codeFormulaX
								if (xPred.getVars().get(0).getColName() != null) {// c'est un string
									nomsX = "nomsX = paste(\'"+xPred.getVars().get(0).getColName()+"\'";
								} else {// c'est un entier
									nomsX  = "nomsX = paste(colnames(mml_data)[" + xPred.getVars().get(0).getColumn()+"]";
								}
								for (var i = 1; i < xPred.getVars().size(); i++) {
									// xPred.getVars().get(i)
									if (xPred.getVars().get(i).getColName() !== null) {// c'est un string
										nomsX += ",\' + \',";
										nomsX += "\'" + xPred.getVars().get(i).getColName()+"\'";
									} else {// c'est un entier
										nomsX += ",\' + \',";
										nomsX += "colnames(mml_data)[" + xPred.getVars().get(i).getColumn()+"]";
									}

								}
								if (xPred.getVars().get(0).getColName() != null) {// c'est un string
									nomsX += ")\n";
								} else {// c'est un entier
									nomsX += ")\n";
								}

							}
						} else {// la prédictive a été donnée
							println("Predictive renseignee");
							if (y.getColName() != null) { // si colname est un string
								println("Predictive est un string");
								nomY = "nomY = \'"+y.getColName()+"\'\n";
								nbPredictive = "nbPredictive = which(colnames(mml_data) == \'"+y.getColName()+"\')\n";
								if (x instanceof AllVariables) {
									println("Toutes les variables sont explicatives");
									nomsX = "nomsX = \'.\'\n";
								}
							} else { //// si colname est un int
								println("Predictive est un int");
								nomY = "nomY = colnames(mml_data)[" +y.getColumn()+"] \n";
								nbPredictive = "nbPredictive = "+y.getColumn()+"\n";

								if (x instanceof AllVariables) {
									println("Toutes les variables sont explicatives");
									nomsX = "nomsX = \'.\'\n";									  
								}
							}
								if (x instanceof PredictorVariables) {
									// PredictorVariables
									println("Des variables explicatives ont été données");
									val xPred = x as PredictorVariables;
									// on initialise codeFormulaX
									if (xPred.getVars().get(0).getColName() != null) {// c'est un string
										nomsX = "nomsX = paste(\'"+xPred.getVars().get(0).getColName()+"\'";
									} else {// c'est un entier
										nomsX  = "nomsX = paste(colnames(mml_data)[" + xPred.getVars().get(0).getColumn()+"]";
									}
									for (var i = 1; i < xPred.getVars().size(); i++) {
										// xPred.getVars().get(i)
										if (xPred.getVars().get(i).getColName() != null) {// c'est un string
											nomsX += ",\' + \',";
											nomsX += "\'" + xPred.getVars().get(i).getColName()+"\'";
										} else {// c'est un entier
											nomsX += ",\' + \',";
											nomsX += "colnames(mml_data)[" + xPred.getVars().get(i).getColumn()+"]";
										}

									}
									if (xPred.getVars().get(0).getColName() != null) {// c'est un string
										nomsX += ")\n";
									} else {// c'est un entier
										nomsX += ")\n";
									}

								}


						}
					}
					var formuleComplete = nomsX + nomY + "formule = paste(nomY, \'~\',nomsX)\n";
					formuleComplete += "formule = as.formula(formule)\n";

					println("Validation");
					/* LA VALIDATION */
					val validationR = m.getValidation();
					val stratificationR = validationR.getStratification();
					// LA METRIQUE
					// ValidationMetric metric = validation;


					val metricR = validationR.getMetric();
					var metricCodeR = "";
					println("Metrique");
					for (var i = 0; i < metricR.size(); i++) {
						if (ValidationMetric.RECALL.equals(metricR.get(i))) {
							metricCodeR += "print(paste(\"Recall = \",recall))\n";
						} else if (ValidationMetric.PRECISION.equals(metricR.get(i))) {
							metricCodeR += "print(paste(\"Precision = \",precision))\n";
						} else if (ValidationMetric.F1.equals(metricR.get(i))) {
							metricCodeR += "print(paste(\"f1_score = \",f1))\n";
						}
					}

					// LA STRATIFICATION
					var RstratificationCode = "library(MLmetrics)\n";
					println("Stratification");
					if (stratificationR instanceof CrossValidation) {// c'est de la crossValidation
						println("CrossValidation");
						var cross = stratificationR as CrossValidation;
						val numRep = cross.getNumber();
						// créer le x_train et le y_train
						RstratificationCode += "library(caret)\n";
						RstratificationCode += "folds <- createFolds(factor(mml_data$variety), k = " + numRep + ", list = TRUE, returnTrain = TRUE)\n";
						RstratificationCode += "f1 <- 0\n";
						RstratificationCode += "recall <- 0\n";
						RstratificationCode += "precision <- 0\n";
						RstratificationCode += "for(test_ind in folds){\n";
						RstratificationCode += "train <- mml_data[-test_ind, ]\n";
						RstratificationCode += "test <- mml_data[test_ind, ]\n";
						RstratificationCode += "x_test <- test[,-nbPredictive]\n";
						RstratificationCode += "y_test <- test[,nbPredictive]\n";
						RstratificationCode += RalgoML;
						RstratificationCode += "ypred <- predict(classifier,test,type='class')\n";
						RstratificationCode += "f1 <- f1 + F1_Score(y_test, ypred, positive = NULL)\n";
						RstratificationCode += "recall <- recall + Recall(y_test, ypred, positive = NULL)\n";
						RstratificationCode += "precision <- precision + Precision(y_test, ypred, positive = NULL)\n";
						RstratificationCode += "}\n";
						RstratificationCode += "recall = recall/length(folds)\n";
						RstratificationCode += "f1 = f1/length(folds)\n";
						RstratificationCode += "precision = f1/length(folds)\n";

					} else {// c'est du TrainingTest
						println("TrainingTest");
						var trainTestR = stratificationR as TrainingTest;
						var pourcentageTraining = trainTestR.getNumber();
						var pourcentage = (100 - pourcentageTraining * 1.0 )/100;
						println(pourcentage);
						RstratificationCode += "pourcentage = "+pourcentage+"\n";
						RstratificationCode += "test_ind <- sample(seq_len(nrow(mml_data)), size = pourcentage*nrow(mml_data))\n";
						RstratificationCode += "train <- mml_data[-test_ind, ]\n";
						RstratificationCode += "test <- mml_data[test_ind, ]\n";
						RstratificationCode += "x_test <- test[,-nbPredictive]\n";
						RstratificationCode += "y_test <- test[,nbPredictive]\n";
						RstratificationCode += RalgoML;
						RstratificationCode += "ypred <- predict(classifier,x_test,type=\"class\")\n";
						RstratificationCode += "f1 <- F1_Score(y_test, ypred, positive = NULL)\n";
						RstratificationCode += "recall <- Recall(y_test, ypred, positive = NULL)\n";
						RstratificationCode += " precision <- Precision(y_test, ypred, positive = NULL)\n";

					}

					// variable predicitive par defaut est la derniere du tableau
					// FrameworkLang framework = mlAlgorithm.getFramework();
					RCode += "\nprint (mml_data)\n";
					RCode += formuleComplete;
					RCode += nbPredictive;
					RCode += RstratificationCode;
					RCode += metricCodeR;
					
				return RCode; 
				}
					
//				case R:
//					String readCsv = "mml_data <- read.csv(" + mkValueInSingleQuote(fileLocation) + ", sep="
//							+ mkValueInSingleQuote(csv_separator.getLiteral()) + ")\n";
//					String codeR = "" + readCsv;
//					RFormula formulaR = result.getFormula();
//					println("formule R : ");
//					if(algo instanceof RandomForest) {
//						codeR += "library(randomForest)\n"
//								+ "modelRF <- randomForest(formula=" + formulaR.toString() + ",data=mml_data)\n"
//										+ "print(modelRF)";
//					}
//					Files.write(codeR.getBytes(), new File("mml.R"));
//					// end of R generation
//
//					/*
//					 * Calling generated R script (basic solution through systems call) we
//					 * assume that "R" is in the path
//					 */
//					Process pR = Runtime.getRuntime().exec("Rscript mml.R");
//					BufferedReader inR = new BufferedReader(new InputStreamReader(pR.getInputStream()));
//					String lineR;
//					while ((lineR = inR.readLine()) != null) {
//						println(lineR);
//					}
//					break;
				return "";

	}
		
	private def compile(MMLModel m) {
		val dataInput = m.getInput();
		val fileLocation = dataInput.getFilelocation();
	
		
		val pythonImport = "import pandas as pd\n"; 
		val DEFAULT_COLUMN_SEPARATOR = ","; // by default
		var csv_separator = DEFAULT_COLUMN_SEPARATOR;
		val parsingInstruction = dataInput.getParsingInstruction();
		if (parsingInstruction !== null) {			
			System.err.println("parsing instruction..." + parsingInstruction);
			csv_separator = parsingInstruction.getSep().toString();
		}
		val csvReading = "mml_data = pd.read_csv(" + mkValueInSingleQuote(fileLocation) + ", sep=" + mkValueInSingleQuote(csv_separator) + ")";						
		var pandasCode = pythonImport + csvReading;
		
		pandasCode += "\nprint (mml_data)\n"; 
		return pandasCode
	}
	
	private def mkValueInSingleQuote(String v) {
		"'" + v + "'"
	}
	
		
}
